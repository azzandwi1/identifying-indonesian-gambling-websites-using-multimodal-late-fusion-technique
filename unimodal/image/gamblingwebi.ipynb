{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10549170,"sourceType":"datasetVersion","datasetId":6527093}],"dockerImageVersionId":30887,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision.transforms as transforms\nimport torchvision.models as models\nfrom tqdm import tqdm\nfrom torch.utils.data import DataLoader, Dataset\nfrom PIL import Image\nfrom sklearn.model_selection import train_test_split","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-02-09T14:01:53.062183Z","iopub.execute_input":"2025-02-09T14:01:53.062587Z","iopub.status.idle":"2025-02-09T14:01:56.235494Z","shell.execute_reply.started":"2025-02-09T14:01:53.062554Z","shell.execute_reply":"2025-02-09T14:01:56.234807Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Seed untuk reproducibility\nseed = 42\ntorch.manual_seed(seed)\nnp.random.seed(seed)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Parameter\nbatch_size = 16\nimg_size = (380, 380)\nepochs = 50\nlearning_rate = 0.0001","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T14:01:56.236548Z","iopub.execute_input":"2025-02-09T14:01:56.236949Z","iopub.status.idle":"2025-02-09T14:01:56.290821Z","shell.execute_reply.started":"2025-02-09T14:01:56.236914Z","shell.execute_reply":"2025-02-09T14:01:56.289949Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Fungsi untuk memuat dataset\ndef load_dataset(path, folders):\n    data = []\n    labels = []\n    for idx, folder in enumerate(folders):\n        folderpath = os.path.join(path, folder)\n        for file in os.listdir(folderpath):\n            data.append(os.path.join(folderpath, file))\n            labels.append(idx)\n    return pd.DataFrame({'imgpath': data, 'labels': labels})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T14:01:56.292496Z","iopub.execute_input":"2025-02-09T14:01:56.292734Z","iopub.status.idle":"2025-02-09T14:01:56.297148Z","shell.execute_reply.started":"2025-02-09T14:01:56.292712Z","shell.execute_reply":"2025-02-09T14:01:56.296282Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Path dataset\npath = '/kaggle/input/gamblingsitesid-img2/gamblingsitesid'\nfolders = ['judi_resized', 'non-judi_resized']\n\n# Load dataset\ndataset = load_dataset(path, folders)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T14:01:56.298426Z","iopub.execute_input":"2025-02-09T14:01:56.298716Z","iopub.status.idle":"2025-02-09T14:01:56.324528Z","shell.execute_reply.started":"2025-02-09T14:01:56.298688Z","shell.execute_reply":"2025-02-09T14:01:56.323729Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Membagi dataset menjadi train, validation, dan test\ntrain_df, temp_df = train_test_split(dataset, train_size=0.8, stratify=dataset['labels'], random_state=seed)\nval_df, test_df = train_test_split(temp_df, train_size=0.5, stratify=temp_df['labels'], random_state=seed)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T14:01:56.325387Z","iopub.execute_input":"2025-02-09T14:01:56.325626Z","iopub.status.idle":"2025-02-09T14:01:56.334332Z","shell.execute_reply.started":"2025-02-09T14:01:56.325607Z","shell.execute_reply":"2025-02-09T14:01:56.333498Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Transformasi data\ntransform = transforms.Compose([\n    transforms.Resize(img_size),\n    transforms.RandomHorizontalFlip(),\n    transforms.ColorJitter(brightness=0.2),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T14:01:56.335063Z","iopub.execute_input":"2025-02-09T14:01:56.335273Z","iopub.status.idle":"2025-02-09T14:01:56.348730Z","shell.execute_reply.started":"2025-02-09T14:01:56.335254Z","shell.execute_reply":"2025-02-09T14:01:56.348007Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Dataset PyTorch\nclass ImageDataset(Dataset):\n    def __init__(self, dataframe, transform=None):\n        self.dataframe = dataframe\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.dataframe)\n\n    def __getitem__(self, idx):\n        img_path = self.dataframe.iloc[idx]['imgpath']\n        label = self.dataframe.iloc[idx]['labels']\n        image = Image.open(img_path).convert('RGB')\n        if self.transform:\n            image = self.transform(image)\n        return image, label\n\ntrain_data = ImageDataset(train_df, transform=transform)\nval_data = ImageDataset(val_df, transform=transform)\ntest_data = ImageDataset(test_df, transform=transform)\n\ntrain_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False)\ntest_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T14:01:56.349471Z","iopub.execute_input":"2025-02-09T14:01:56.349713Z","iopub.status.idle":"2025-02-09T14:01:56.364202Z","shell.execute_reply.started":"2025-02-09T14:01:56.349684Z","shell.execute_reply":"2025-02-09T14:01:56.363537Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Fungsi untuk membangun model\ndef build_model(freeze_base=False, use_pretrained=True):\n    weights = models.EfficientNet_B4_Weights.DEFAULT if use_pretrained else None\n    model = models.efficientnet_b4(weights=weights)\n\n    if freeze_base:\n        for param in model.features.parameters():\n            param.requires_grad = False\n    \n    model.classifier = nn.Sequential(\n        nn.Linear(model.classifier[1].in_features, 512),\n        nn.ReLU(),\n        nn.Dropout(0.3),\n        nn.Linear(512, 1),\n        nn.Sigmoid()\n    )\n    return model.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T14:01:56.366136Z","iopub.execute_input":"2025-02-09T14:01:56.366324Z","iopub.status.idle":"2025-02-09T14:01:56.383621Z","shell.execute_reply.started":"2025-02-09T14:01:56.366308Z","shell.execute_reply":"2025-02-09T14:01:56.382957Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def train_model(model, train_loader, val_loader, epochs=50, lr=0.0001, patience=5):\n    criterion = nn.BCELoss()\n    optimizer = optim.Adam(model.parameters(), lr=lr)\n    \n    best_acc = 0\n    counter = 0  # Early stopping counter\n    history = {'loss': [], 'val_loss': [], 'accuracy': [], 'val_accuracy': []}\n\n    for epoch in range(epochs):\n        model.train()\n        running_loss, correct, total = 0.0, 0, 0\n\n        # Progress bar untuk training\n        train_loader_tqdm = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\", leave=True)\n        \n        for images, labels in train_loader_tqdm:\n            images, labels = images.to(device), labels.float().to(device)\n            optimizer.zero_grad()\n            outputs = model(images).squeeze(1)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n            running_loss += loss.item()\n            predicted = (outputs > 0.5).float()\n            correct += (predicted == labels).sum().item()\n            total += labels.size(0)\n\n            # Update progress bar\n            train_loader_tqdm.set_postfix(loss=loss.item(), acc=correct/total)\n        \n        train_loss = running_loss / len(train_loader)\n        train_acc = correct / total\n\n        # Evaluasi di validation set\n        model.eval()\n        val_loss, correct, total = 0.0, 0, 0\n\n        with torch.no_grad():\n            for images, labels in val_loader:\n                images, labels = images.to(device), labels.float().to(device)\n                outputs = model(images).squeeze(1)\n                loss = criterion(outputs, labels)\n                val_loss += loss.item()\n                predicted = (outputs > 0.5).float()\n                correct += (predicted == labels).sum().item()\n                total += labels.size(0)\n        \n        val_loss /= len(val_loader)\n        val_acc = correct / total\n\n        # Tampilkan hasil epoch\n        print(f\"Epoch {epoch+1}/{epochs} | Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f} | Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f}\")\n\n        # # Simpan model terbaik\n        # if val_acc > best_acc:\n        #     best_acc = val_acc\n        #     torch.save(model.state_dict(), 'best_model.pth')\n        #     counter = 0  # Reset counter karena ada peningkatan akurasi validasi\n        # else:\n        #     counter += 1  # Tambah counter jika akurasi validasi tidak meningkat\n        #     print(f\"Early Stopping Counter: {counter}/{patience}\")\n\n        # # Cek apakah training harus dihentikan\n        # if counter >= patience:\n        #     print(\"Early stopping triggered. Training stopped.\")\n        #     break\n        # Simpan model terbaik berdasarkan val_loss terkecil\n        if val_loss < best_loss:\n            best_loss = val_loss\n            torch.save(model.state_dict(), 'best_model.pth')\n            counter = 0  # Reset counter karena ada peningkatan performa validasi\n        else:\n            counter += 1  # Tambah counter jika val_loss tidak berkurang\n            print(f\"Early Stopping Counter: {counter}/{patience}\")\n        \n        # Cek apakah training harus dihentikan\n        if counter >= patience:\n            print(\"Early stopping triggered. Training stopped.\")\n            break\n            \n        history['loss'].append(train_loss)\n        history['accuracy'].append(train_acc)\n        history['val_loss'].append(val_loss)\n        history['val_accuracy'].append(val_acc)\n\n    print(f\"Best Validation Accuracy: {best_acc:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T14:01:56.384680Z","iopub.execute_input":"2025-02-09T14:01:56.384943Z","iopub.status.idle":"2025-02-09T14:01:56.396213Z","shell.execute_reply.started":"2025-02-09T14:01:56.384924Z","shell.execute_reply":"2025-02-09T14:01:56.395511Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Fungsi untuk evaluasi\ndef evaluate_model(model, test_loader):\n    model.load_state_dict(torch.load('best_model.pth'))\n    model.eval()\n    correct, total = 0, 0\n    with torch.no_grad():\n        for images, labels in test_loader:\n            images, labels = images.to(device), labels.float().to(device)\n            outputs = model(images).squeeze(1)\n            predicted = (outputs > 0.5).float()\n            correct += (predicted == labels).sum().item()\n            total += labels.size(0)\n    print(f\"Test Accuracy: {correct / total:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T14:01:56.396911Z","iopub.execute_input":"2025-02-09T14:01:56.397194Z","iopub.status.idle":"2025-02-09T14:01:56.414133Z","shell.execute_reply.started":"2025-02-09T14:01:56.397167Z","shell.execute_reply":"2025-02-09T14:01:56.413394Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Eksperimen 1: Tanpa pretrained model\nprint(\"Eksperimen 1: Tanpa Pretrained Model\")\nmodel_no_pretrain = build_model(use_pretrained=False)\ntrain_model(model_no_pretrain, train_loader, val_loader)\nevaluate_model(model_no_pretrain, test_loader)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T14:01:56.414844Z","iopub.execute_input":"2025-02-09T14:01:56.415124Z","iopub.status.idle":"2025-02-09T14:37:15.182609Z","shell.execute_reply.started":"2025-02-09T14:01:56.415088Z","shell.execute_reply":"2025-02-09T14:37:15.181701Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Eksperimen 2: Fine-tuning hanya fully connected layer\nprint(\"\\nEksperimen 2: Fine-tuning Fully Connected Layer\")\nmodel_freeze_base = build_model(freeze_base=True, use_pretrained=True)\ntrain_model(model_freeze_base, train_loader, val_loader)\nevaluate_model(model_freeze_base, test_loader)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T14:37:15.183456Z","iopub.execute_input":"2025-02-09T14:37:15.183754Z","iopub.status.idle":"2025-02-09T14:53:19.508035Z","shell.execute_reply.started":"2025-02-09T14:37:15.183723Z","shell.execute_reply":"2025-02-09T14:53:19.507265Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Eksperimen 3: Fine-tuning seluruh jaringan\nprint(\"\\nEksperimen 3: Fine-tuning Seluruh Jaringan\")\nmodel_fine_tune_all = build_model(freeze_base=False, use_pretrained=True)\ntrain_model(model_fine_tune_all, train_loader, val_loader)\nevaluate_model(model_fine_tune_all, test_loader)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T14:53:19.508774Z","iopub.execute_input":"2025-02-09T14:53:19.509094Z","iopub.status.idle":"2025-02-09T15:18:17.248784Z","shell.execute_reply.started":"2025-02-09T14:53:19.509061Z","shell.execute_reply":"2025-02-09T15:18:17.247887Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Fungsi untuk plotting hasil training\ndef plot_training_history(history, title):\n    fig, ax = plt.subplots(1, 2, figsize=(15, 5))\n    \n    # Plot accuracy\n    ax[0].plot(history.history['accuracy'], label='Train Accuracy')\n    ax[0].plot(history.history['val_accuracy'], label='Validation Accuracy')\n    ax[0].set_title(f'{title} - Accuracy')\n    ax[0].set_xlabel('Epoch')\n    ax[0].set_ylabel('Accuracy')\n    ax[0].legend()\n    ax[0].grid(alpha=0.2)\n    \n    # Plot loss\n    ax[1].plot(history.history['loss'], label='Train Loss')\n    ax[1].plot(history.history['val_loss'], label='Validation Loss')\n    ax[1].set_title(f'{title} - Loss')\n    ax[1].set_xlabel('Epoch')\n    ax[1].set_ylabel('Loss')\n    ax[1].legend()\n    ax[1].grid(alpha=0.2)\n    \n    plt.show()\n\n# Plot hasil eksperimen 1: Tanpa pretrained model\nplot_training_history(history_no_pretrain, \"No Pretrained Model\")\n\n# Plot hasil eksperimen 2: Fine-tuning hanya fully connected layer\nplot_training_history(history_freeze_base, \"Freeze Base Model\")\n\n# Plot hasil eksperimen 3: Fine-tuning seluruh jaringan\nplot_training_history(history_fine_tune_all, \"Fine-tune All Layers\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T15:19:01.284829Z","iopub.execute_input":"2025-02-09T15:19:01.285151Z","iopub.status.idle":"2025-02-09T15:19:01.351976Z","shell.execute_reply.started":"2025-02-09T15:19:01.285124Z","shell.execute_reply":"2025-02-09T15:19:01.350973Z"}},"outputs":[],"execution_count":null}]}